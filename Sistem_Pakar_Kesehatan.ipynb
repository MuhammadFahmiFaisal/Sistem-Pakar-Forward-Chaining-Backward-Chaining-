{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlWKQoPP4Zup",
        "outputId": "56c6ebbc-d10b-4fa9-95a5-fe649e26ac4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting experta\n",
            "  Downloading experta-1.9.4-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting frozendict==1.2 (from experta)\n",
            "  Downloading frozendict-1.2.tar.gz (2.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting schema==0.6.7 (from experta)\n",
            "  Downloading schema-0.6.7-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Downloading experta-1.9.4-py3-none-any.whl (35 kB)\n",
            "Downloading schema-0.6.7-py2.py3-none-any.whl (14 kB)\n",
            "Building wheels for collected packages: frozendict\n",
            "  Building wheel for frozendict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for frozendict: filename=frozendict-1.2-py3-none-any.whl size=3149 sha256=4195577d9e9e8ed76e64ece5abcf212bfee5ce00178f8954b9c9a22fbb357b11\n",
            "  Stored in directory: /root/.cache/pip/wheels/49/ac/f8/cb8120244e710bdb479c86198b03c7b08c3c2d3d2bf448fd6e\n",
            "Successfully built frozendict\n",
            "Installing collected packages: schema, frozendict, experta\n",
            "  Attempting uninstall: frozendict\n",
            "    Found existing installation: frozendict 2.4.6\n",
            "    Uninstalling frozendict-2.4.6:\n",
            "      Successfully uninstalled frozendict-2.4.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yfinance 0.2.55 requires frozendict>=2.3.4, but you have frozendict 1.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed experta-1.9.4 frozendict-1.2 schema-0.6.7\n"
          ]
        }
      ],
      "source": [
        "!pip install experta"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade frozendict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYr0I6Mr5V0W",
        "outputId": "0756aeab-f593-4457-fb51-8241d38c345d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: frozendict in /usr/local/lib/python3.11/dist-packages (1.2)\n",
            "Collecting frozendict\n",
            "  Downloading frozendict-2.4.6-py311-none-any.whl.metadata (23 kB)\n",
            "Downloading frozendict-2.4.6-py311-none-any.whl (16 kB)\n",
            "Installing collected packages: frozendict\n",
            "  Attempting uninstall: frozendict\n",
            "    Found existing installation: frozendict 1.2\n",
            "    Uninstalling frozendict-1.2:\n",
            "      Successfully uninstalled frozendict-1.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "experta 1.9.4 requires frozendict==1.2, but you have frozendict 2.4.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed frozendict-2.4.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from experta import *\n",
        "\n",
        "class Diagnosis(KnowledgeEngine):\n",
        "\n",
        "  @Rule(Fact(cough=True) & Fact(fever=True) & Fact(fatigue=True))\n",
        "  def flu(self):\n",
        "    print(\"Diagnosis : You may have the Flu.\")\n",
        "\n",
        "  @Rule(Fact(cough=True) & Fact(fever=True) & Fact(breathing_difficulty=True))\n",
        "  def pneumonia(self):\n",
        "    print(\"Diagnosis : You may have Pneumonia.\")\n",
        "\n",
        "  @Rule(Fact(sneezing=True) & Fact(runny_nose=True) & Fact(cough=False))\n",
        "  def cold(self):\n",
        "    print(\"Diagnosis : You may have a Common Cold.\")\n",
        "  @Rule(Fact(sore_throat=True) & Fact(fever=True))\n",
        "  def throat_infection(self):\n",
        "    print(\"Diagnosis : You may have a Throat Infection.\")\n",
        "  @Rule(Fact(cough=True) & Fact(fever=False) & Fact(fatigue=False))\n",
        "  def healthy(self):\n",
        "    print(\"Diagnosis : You seem to be healthy.\")\n",
        "\n",
        "def get_input():\n",
        "    \"\"\"Helper function to get user input as boolean (yes/no).\"\"\"\n",
        "    def ask_question(question):\n",
        "        return input(question + \" (yes/no): \") .strip() .lower() == \"yes\"\n",
        "\n",
        "    return {\n",
        "        \"cough\": ask_question(\"Do you have a cough?\"),\n",
        "        \"fever\": ask_question(\"Do you have a fever?\"),\n",
        "        \"fatigue\": ask_question(\"Do you feel fatigued?\"),\n",
        "        \"breathing_difficulty\": ask_question(\"Do you have breathing difficulty?\"),\n",
        "        \"sneezing\": ask_question(\"Are yo sneezing?\"),\n",
        "        \"runny_nose\": ask_question(\"Do you have a runny nose?\"),\n",
        "        \"sore_throat\": ask_question(\"Do you have a sore throat?\")\n",
        "    }\n",
        "\n",
        "#Running the expert system\n",
        "if __name__ == \"__main__\":\n",
        "    symptoms = get_input()\n",
        "    engine = Diagnosis()\n",
        "    engine.reset() #Reset the knowledge engine\n",
        "\n",
        "    for symptom, present in symptoms.items():\n",
        "        engine.declare(Fact(**{symptom: present})) #Declare facts\n",
        "\n",
        "    engine.run() #Run the inference engine"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9wwYvia6CSe",
        "outputId": "ab94dd5a-ecdd-4e06-981d-e4d89fe119b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Do you have a cough? (yes/no): no\n",
            "Do you have a fever? (yes/no): no\n",
            "Do you feel fatigued? (yes/no): no\n",
            "Do you have breathing difficulty? (yes/no): no\n",
            "Are yo sneezing? (yes/no): no\n",
            "Do you have a runny nose? (yes/no): no\n",
            "Do you have a sore throat? (yes/no): no\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from experta import *\n",
        "\n",
        "class SistemPakarMedis(KnowledgeEngine):\n",
        "\n",
        "    @Rule(Fact(demam=True) & Fact(batuk=True))\n",
        "    def flu(self):\n",
        "        print(\"Diagnosis : Anda menderita flu.\")\n",
        "\n",
        "    @Rule(Fact(sakit_tenggorokan=True) & Fact(demam=True))\n",
        "    def throat_infection(self):\n",
        "        print(\"Diagnosis : Anda menderita Radang Tenggorokan.\")\n",
        "\n",
        "#Running the expert system\n",
        "engine = SistemPakarMedis()\n",
        "engine.reset()\n",
        "engine.declare(Fact(demam=True))\n",
        "engine.declare(Fact(sakit_tenggorokan=True)) #Input System\n",
        "engine.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnOv45f7DKgJ",
        "outputId": "3477ca6b-2261-400c-b10c-cbf59e4c6967"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Diagnosis : Anda menderita Radang Tenggorokan.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_chaining(fact, rules):\n",
        "  inferred = set(fact)\n",
        "  changed = True\n",
        "  while changed:\n",
        "        changed = False\n",
        "        for rule in rules:\n",
        "            if rule[\"if\"].issubset(inferred) and rule[\"then\"] not in inferred:\n",
        "                inferred.add(rule[\"then\"])\n",
        "                changed = True\n",
        "  return inferred\n",
        "\n",
        "facts = {\"has_feathers\", \"can_fly\", \"lays_eggs\"}\n",
        "rules = [\n",
        "    {\"if\": {\"has_feathers\", \"can_fly\"}, \"then\": \"is_bird\"},\n",
        "    {\"if\": {\"lays_eggs\", \"is_bird\"}, \"then\": \"is_chicken\"}\n",
        "]\n",
        "\n",
        "result = forward_chaining(facts, rules)\n",
        "print(\"inferred facts:\", result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZScMH_dIALG",
        "outputId": "c2f34434-eb3a-4b20-935a-93602aa5d8a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inferred facts: {'lays_eggs', 'is_chicken', 'can_fly', 'has_feathers', 'is_bird'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def backward_chaining(goal, facts, rules):\n",
        "    if goal in facts:\n",
        "        return True\n",
        "    for rule in rules:\n",
        "        if rule[\"then\"] == goal:\n",
        "            if all(backward_chaining(cond, facts, rules) for cond in rule[\"if\"]):\n",
        "                return True\n",
        "    return False\n",
        "\n",
        "facts = {\"likes_computers\", \"solves_problems\"}\n",
        "rules = [\n",
        "    {\"if\": {\"likes_computers\", \"solves_problems\"}, \"then\": \"should_be_engineer\"},\n",
        "    {\"if\": {\"should_be_engineer\", \"like_programming\"}, \"then\": \"software_engineer\"}\n",
        "]\n",
        "\n",
        "goal = \"software_engineer\"\n",
        "result = backward_chaining(goal, facts, rules)\n",
        "print(f\"Is '{goal}' provable? ->\", result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlUrEJF1NEAv",
        "outputId": "d7c9c98e-0d6b-48db-8d52-8efb071a513f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is 'software_engineer' provable? -> False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_chaining(fact, rules):\n",
        "  inferred = set(fact)\n",
        "  changed = True\n",
        "  while changed:\n",
        "        changed = False\n",
        "        for rule in rules:\n",
        "            if rule[\"if\"].issubset(inferred) and rule[\"then\"] not in inferred:\n",
        "                inferred.add(rule[\"then\"])\n",
        "                changed = True\n",
        "  return inferred\n",
        "\n",
        "facts = {\"has_wheels\", \"has_engine\", \"has_two_wheels\"}\n",
        "rules = [\n",
        "    {\"if\": {\"has_wheels\", \"has_engine\"}, \"then\": \"is_vehicle\"},\n",
        "    {\"if\": {\"is_vehicle\", \"has_two_wheels\"}, \"then\": \"is_motorcycle\"},\n",
        "    {\"if\": {\"is_vehicle\", \"has_four_wheels\"}, \"then\": \"is_car\"}\n",
        "]\n",
        "\n",
        "result = forward_chaining(facts, rules)\n",
        "print(\"inferred facts:\", result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypqLckefRlhO",
        "outputId": "2137af66-efcf-4f86-f790-ded8cc60f463"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inferred facts: {'solves_problems', 'should_be_engineer', 'likes_computers'}\n"
          ]
        }
      ]
    }
  ]
}